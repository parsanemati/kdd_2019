{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygame import mixer # Load the required library\n",
    "from threading import Timer\n",
    "def Stop():\n",
    "    mixer.music.stop()\n",
    "def play():\n",
    "    mixer.init()\n",
    "    mixer.music.load('/home/alinemati/Yandex.Disk/MUSIC/Daya - Insomnia.mp3')\n",
    "    mixer.music.play()\n",
    "\n",
    "\n",
    "play()\n",
    "t = Timer(180.0, Stop)\n",
    "t.start() # after 120 seconds, \"hello, world\" will be printed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[86]:\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# original lang\n",
    "# http://scikit-learn.org/stable/modules/multiclass.html\n",
    "# Support multilabel:\n",
    "# http://scikit-learn.org/stable/supervised_learning.html\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "start = time.time()\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import *\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBClassifier\n",
    "import datetime\n",
    "#whole clf\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# clf3 = LogisticRegression()\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf4 40 = LogisticRegressionCV(random_state=0)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score \n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# end = time.time()\n",
    "# hours, rem = divmod(end-start, 3600)\n",
    "# minutes, seconds = divmod(rem, 60)\n",
    "# print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "# today = datetime.date.today() # now time\n",
    "# print(today) # today date\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/alinemati/Yandex.Disk/Compitition/2019/KDD2019/Data/Result/new_round_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>o_Long</th>\n",
       "      <th>o_Lat</th>\n",
       "      <th>d_long</th>\n",
       "      <th>d_lat</th>\n",
       "      <th>distAnce</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>...</th>\n",
       "      <th>eta_min</th>\n",
       "      <th>eta_std</th>\n",
       "      <th>click</th>\n",
       "      <th>mode1</th>\n",
       "      <th>mode2</th>\n",
       "      <th>mode3</th>\n",
       "      <th>mode4</th>\n",
       "      <th>mode5</th>\n",
       "      <th>mode6</th>\n",
       "      <th>mode7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid  date  time  o_Long  o_Lat  d_long  d_lat  distAnce  p0  p1  ...  \\\n",
       "0    2     1     3    51.0   30.0    50.0   30.0       1.0   2   2  ...   \n",
       "1   10     1     3    61.0   41.0    39.0   30.0      13.0   1   0  ...   \n",
       "2   21     1     3    47.0   28.0    43.0   27.0       2.0   0   0  ...   \n",
       "3   25     1     1    53.0   28.0    52.0   27.0       1.0   0   0  ...   \n",
       "4   34     1     3    45.0   40.0    52.0   31.0      10.0   2   2  ...   \n",
       "\n",
       "   eta_min  eta_std  click  mode1  mode2  mode3  mode4  mode5  mode6  mode7  \n",
       "0      0.0      0.0      0      0      0      0      0      0      0      0  \n",
       "1     12.0      4.0      1      2      3      4      8     11      1      0  \n",
       "2      2.0      0.0      2      2      3      4      0      0      0      0  \n",
       "3      1.0      3.0      1      1      3      4      6      1      5      0  \n",
       "4      9.0      3.0      9      9      3      4      7      2      0      0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(path+'merged_all_ful_for_traing_rounded.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 93)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 92)\n",
      "   date  time  o_Long  o_Lat  d_long  d_lat  distAnce  p0  p1  p2  ...  \\\n",
      "0     1     3    51.0   30.0    50.0   30.0       1.0   2   2   2  ...   \n",
      "1     1     3    61.0   41.0    39.0   30.0      13.0   1   0   0  ...   \n",
      "2     1     3    47.0   28.0    43.0   27.0       2.0   0   0   0  ...   \n",
      "3     1     1    53.0   28.0    52.0   27.0       1.0   0   0   1  ...   \n",
      "4     1     3    45.0   40.0    52.0   31.0      10.0   2   2   2  ...   \n",
      "\n",
      "   eta_min  eta_std  click  mode1  mode2  mode3  mode4  mode5  mode6  mode7  \n",
      "0      0.0      0.0      0      0      0      0      0      0      0      0  \n",
      "1     12.0      4.0      1      2      3      4      8     11      1      0  \n",
      "2      2.0      0.0      2      2      3      4      0      0      0      0  \n",
      "3      1.0      3.0      1      1      3      4      6      1      5      0  \n",
      "4      9.0      3.0      9      9      3      4      7      2      0      0  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_YouTube = data.loc[:,['date', 'time', 'o_Long', 'o_Lat', 'd_long', 'd_lat', 'distAnce', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'distance_avg', 'distance_max', 'distance_min', 'distance_std', 'price_avg', 'price_max', 'price_std', 'eta_avg', 'eta_max', 'eta_min', 'eta_std', 'click', 'mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6', 'mode7']]\n",
    "print(data_YouTube.shape)\n",
    "print(data_YouTube.head())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (400000, 91)\n",
      "x_test: (100000, 91)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Splitting the data into 300 training instances and 104 test instances\n",
    "n = 100000\n",
    "all_Ids = np.arange(len(data_YouTube))\n",
    "# print(all_Ids.shape)\n",
    "# random.shuffle(all_Ids)\n",
    "test_Ids = all_Ids[0:n]\n",
    "train_Ids = all_Ids[n:]\n",
    "data_test = data_YouTube.loc[test_Ids, :]\n",
    "data_train = data_YouTube.loc[train_Ids, :]\n",
    "# print(data_train.head()) , print(data_test.head())\n",
    "\n",
    "# print('done')\n",
    "X_train = data_train.loc[:, ['date', 'time', 'o_Long', 'o_Lat', 'd_long', 'd_lat', 'distAnce', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'distance_avg', 'distance_max', 'distance_min', 'distance_std', 'price_avg', 'price_max', 'price_std', 'eta_avg', 'eta_max', 'eta_min', 'eta_std', 'mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6', 'mode7']]\n",
    "\n",
    "Y_train = data_train['click']\n",
    "\n",
    "\n",
    "x_test = data_test.loc[:, [ 'date', 'time', 'o_Long', 'o_Lat', 'd_long', 'd_lat', 'distAnce', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'distance_avg', 'distance_max', 'distance_min', 'distance_std', 'price_avg', 'price_max', 'price_std', 'eta_avg', 'eta_max', 'eta_min', 'eta_std', 'mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6', 'mode7']]\n",
    "\n",
    "y_test = data_test['click']\n",
    "# print('done')\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_train:\",X_train.shape) , print(\"x_test:\",x_test.shape)\n",
    "\n",
    "\n",
    "# ensemble = MLPClassifier(hidden_layer_sizes=(50), activation='relu'\n",
    "#                           ,max_iter = 1500 , learning_rate=\"constant\", \n",
    "#                      shuffle=False, solver='adam' , random_state=0 , warm_start=True, tol=0.0001)\n",
    "\n",
    "\n",
    "# ensemble=BaggingClassifier()\n",
    "# clf2=XGBClassifier()\n",
    "\n",
    "\n",
    "# ensemble = VotingClassifier(estimators=[\n",
    "#                                     ('clf0', clf0) , \n",
    "#                                     ('clf1', clf1) , \n",
    "#                                     ('clf2', clf2), \n",
    "# #                                     ('clf3', clf3), \n",
    "# #                                     ('clf4', clf4), \n",
    "# #                                     (\"clf5\" , clf5), \n",
    "# #                                     (\"clf6\" , clf6), \n",
    "#                                    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def mse(X, Y):\n",
    "    MSE=mean_squared_error(X, Y)\n",
    "    return print(\"MSE:\" , MSE)\n",
    "\n",
    "def R2(X, Y):\n",
    "    r_2=r2_score(X, Y)\n",
    "    return print(\"r_2:\" , r_2)\n",
    "\n",
    "def f1_weighted_cross_validate_report(model ,X, Y , cv):\n",
    "    f1=cross_val_score(model ,X, Y, cv=cv ,scoring='f1_weighted' ).mean()\n",
    "    return  print(\"f1_weighted_cross_validate_report:\" , f1 , \" with cv \" , cv)\n",
    "\n",
    "\n",
    "def accuracy_cross_validate_report(model ,X, Y, cv):\n",
    "    acc=cross_val_score(model ,X, Y, cv=cv ,scoring='accuracy' ).mean()\n",
    "    return  print(\"accuracy_cross_validate_report:\", acc , \" with cv \" , cv)\n",
    "\n",
    "\n",
    "def accuracy_real(X,Y):\n",
    "    accuracy_real = accuracy_score(X, Y)*100\n",
    "    return accuracy_real\n",
    "    \n",
    "def  f1score(X , Y): #F1 = 2 * (precision * recall) / (precision + recall)\n",
    "     f1score= f1_score(X , Y, average='weighted')  \n",
    "     return print(\"f1score: \" , f1score)\n",
    "\n",
    "\n",
    "def  recallscore(X,Y ): #tp / (tp + fn)\n",
    "     recall__score= recall__score(X,Y, average='weighted') \n",
    "     return print(\"recall_score: \" , recall_score)\n",
    "\n",
    "                                   \n",
    "def  precisionscore(X , Y ): #tp / (tp + fp)\n",
    "     precision__score= precision_score(X,Y, average='weighted') \n",
    "     return print(\"precision__score: \" , precision__score )\n",
    "\n",
    "def LR_Traning(model, X, Y):\n",
    "    LR_Traning=  model.score(X, Y)\n",
    "    return print(\"LR_Traning:\" , LR_Traning)\n",
    "\n",
    "\n",
    "def prediction(model, X):\n",
    "    predict = model.predict(X)\n",
    "    return print(\"predict\" , predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0= RandomForestClassifier(n_estimators=1200 )\n",
    "# print(clf0)\n",
    "eclf1 = clf0.fit(X_train, Y_train)\n",
    "# prediction( eclf1 , x_test)\n",
    "# LR_Traning( eclf1 , X_train, Y_train)\n",
    "f1_weighted_cross_validate_report(clf0, X_train, Y_train , 5)\n",
    "accuracy_cross_validate_report(clf0, X_train, Y_train , 5)\n",
    "# f1score( X_train, Y_train )\n",
    "# recallscore( X_train, Y_train)\n",
    "# precisionscore( X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bootstrap_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-54e2187d02a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbootstrap\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbase_estimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mbootstrap_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbootstrap_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Round = \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mRound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         clf0= BaggingClassifier(base_estimator=base_estimator, n_estimators=10, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'bootstrap_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Round =1\n",
    "# base_estimator=[None,\n",
    "#                 GradientBoostingClassifier(),\n",
    "#                 XGBClassifier(),\n",
    "#                 DecisionTreeClassifier(),\n",
    "#                 RandomForestClassifier(),\n",
    "#                 ExtraTreesClassifier()]\n",
    "\n",
    "# boole= [True, False]\n",
    "# maxsamples = [1 , 0.5 , 1.5 , 2 , 2.5 , 3 , 4 ,5] \n",
    "# maxfeatures = [1, 2, 4, 6, 7, 8, 10 ,15]\n",
    "# bootstrap= [True, False],\n",
    "# bootstrap_features= [True, False]\n",
    "# for Maxsamples in maxsamples:\n",
    "#     for Maxfeatures in maxfeatures:\n",
    "#         for bootstrap in bootstrap:\n",
    "#             for base_estimator in base_estimator:\n",
    "#                  for bootstrap_features in bootstrap_features:\n",
    "#                         print(\"Round = \" , Round)\n",
    "#                         clf0= BaggingClassifier(base_estimator=base_estimator, n_estimators=10, \n",
    "#                                                 max_samples=Maxsamples, \n",
    "#                                                 max_features=Maxfeatures,\n",
    "#                                                                 bootstrap=bootstrap, \n",
    "#                                                                 bootstrap_features=bootstrap_features, \n",
    "#                                                 oob_score=False, warm_start=True, random_state=0\n",
    "#                                                )\n",
    "#                         eclf1 = clf0.fit(X_train, Y_train)\n",
    "\n",
    "#                         f1_weighted_cross_validate_report(clf0, X_train, Y_train , 5)\n",
    "\n",
    "#                         end = time.time()\n",
    "#                         hours, rem = divmod(end-start, 3600)\n",
    "#                         minutes, seconds = divmod(rem, 60)\n",
    "#                         print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "#                         today = datetime.date.today() # now time\n",
    "#                         print(today) # today date\n",
    "#                         print(\"******************************************************\")\n",
    "#                         Round +=1  \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier\n",
    "\n",
    "XGBClassifier\n",
    "\n",
    "MLPClassifier\n",
    "\n",
    "BaggingClassifier\n",
    "\n",
    "RandomForestClassifier\n",
    "\n",
    "ExtraTreesClassifier\n",
    "\n",
    "GradientBoostingClassifier , XGBClassifier , MLPClassifier, RandomForestClassifier , ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data_YouTube.loc[:, [ 'date', 'time', 'o_Long', 'o_Lat', 'd_long', 'd_lat', 'distAnce', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'distance_avg', 'distance_max', 'distance_min', 'distance_std', 'price_avg', 'price_max', 'price_std', 'eta_avg', 'eta_max', 'eta_min', 'eta_std',  'mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6', 'mode7']]\n",
    "\n",
    "\n",
    "# # X_train.shape\n",
    "\n",
    "\n",
    "# # In[92]:\n",
    "\n",
    "\n",
    "# Y_train = data_YouTube['click']\n",
    "# # print(X_train.shape)\n",
    "# # print(X_train.head())\n",
    "# # Show_Label= Y_train\n",
    "# print('done')\n",
    "\n",
    "# # clf0 = MLPClassifier(hidden_layer_sizes=(30), activation='relu'\n",
    "# #                           ,max_iter = 1500 , learning_rate=\"constant\", \n",
    "# #                      shuffle=False, solver='adam' , random_state=0 , warm_start=True, tol=0.0001)\n",
    "\n",
    "# # clf1 =  GradientBoostingClassifier(max_depth=20)\n",
    "\n",
    "# ensemble =  XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# # clf5 = RandomForestClassifier()\n",
    "# # clf6=GradientBoostingClassifier()\n",
    "# # ensemble = VotingClassifier(estimators=[\n",
    "# #                                     ('clf0', clf0) , \n",
    "# #                                     ('clf1', clf1) , \n",
    "# # #                                     ('clf2', clf2), \n",
    "# # #                                     ('clf3', clf3), \n",
    "# # #                                     ('clf4', clf4), \n",
    "# #                                    ])\n",
    "\n",
    "# eclf1 = ensemble.fit(X_train, Y_train)\n",
    "# # predict = eclf1.predict(x_test)\n",
    "# # \"Done\"\n",
    "\n",
    "# # path='/home/alinemati/Yandex.Disk/Compitition/2019/KDD2019/Data/data_set_phase1/data_set_phase1/Test/Redy_To_test/'\n",
    "# # # np.random.seed(123)\n",
    "\n",
    "# # Reading the data into a dataframe and selecting the columns we need\n",
    "# # data_test_prediction = pd.read_csv(\"merged_all_test.csv\")\n",
    "# data_test_prediction = pd.read_csv(path+\"merged_all_test_round.csv\")\n",
    "\n",
    "# data_test_prediction.head()\n",
    "\n",
    "# data_test= data_test_prediction.loc[:, ['date', 'time', 'o_Long', 'o_Lat', 'd_long', 'd_lat', 'distAnce', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'distance_avg', 'distance_max', 'distance_min', 'distance_std', 'price_avg', 'price_max', 'price_std', 'eta_avg', 'eta_max', 'eta_min', 'eta_std',  'mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6', 'mode7']]\n",
    "# predict = eclf1.predict(data_test)\n",
    "# predict.shape, type(predict)\n",
    "# # np.savetxt(path+'predict_Unknown.csv', predict, delimiter=',') \n",
    "# data_test_prediction_sid=data_test_prediction.loc[:, [\"sid\"]]\n",
    "# data_test_prediction_sid.head()\n",
    "# data_test_prediction_sid.to_csv(path+\"testcsv.csv\", index=False)\n",
    "\n",
    "# predict=pd.DataFrame({'recommend_mode':predict.tolist() })\n",
    "# predict.head()\n",
    "\n",
    "# final_result = pd.concat([data_test_prediction_sid,predict] , sort=False,  axis = 1)\n",
    "# final_result.head()\n",
    "\n",
    "# import datetime\n",
    "\n",
    "# x = datetime.datetime.now()\n",
    "# print(x)\n",
    "\n",
    "# final_result.to_csv(path+\"final_result_ensambel_\",x,\".csv\", index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
